{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to MkDocs","text":"<p>For full documentation visit mkdocs.org.</p>"},{"location":"#commands","title":"Commands","text":"<ul> <li><code>mkdocs new [dir-name]</code> - Create a new project.</li> <li><code>mkdocs serve</code> - Start the live-reloading docs server.</li> <li><code>mkdocs build</code> - Build the documentation site.</li> <li><code>mkdocs -h</code> - Print help message and exit.</li> </ul>"},{"location":"#project-layout","title":"Project layout","text":"<pre><code>mkdocs.yml    # The configuration file.\ndocs/\n    index.md  # The documentation homepage.\n    ...       # Other markdown pages, images and other files.\n</code></pre>"},{"location":"blog/","title":"Blog","text":""},{"location":"deep_learning_models/01_deep_iter/","title":"deep-iter","text":"In\u00a0[\u00a0]: Copied!"},{"location":"deep_learning_models/01_deep_iter/#what-is-cross-attention","title":"What is Cross Attention\u00b6","text":"<p>''' Suppose a $n$-dimensional query vector $q \\in \\mathbb{R}^n $ represent a feature vector, which is affected by / determined by / extracted from a  $(m,n)$-dimensional key vector $k$ and a $(m,n)$-dimensional value vector $v$.</p> <p>First, a vector multiplication operator $(n) \\times (m,n) = (m)$ to get the similarity between the query vector and $m$ key vectors. Then a softmax operator to regularized into a categorical distribution. After that, a vector multiplication operator $(m) \\times (m,n) = (n)$ to extract information from $m$ value vectors and get the new query vector according the similarity between the old query vector and key vectors. '''</p>"},{"location":"species_distribution/01_sdm/","title":"Introduction","text":"In\u00a0[\u00a0]: Copied! <pre>import pandas as pd\nimport geopandas as gpd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nimport matplotlib.pyplot as plt\n</pre>  import pandas as pd import geopandas as gpd from sklearn.model_selection import train_test_split from sklearn.ensemble import RandomForestClassifier from sklearn.metrics import accuracy_score, confusion_matrix import matplotlib.pyplot as plt In\u00a0[\u00a0]: Copied! <pre># \u5047\u8bbe\u4f60\u5df2\u7ecf\u6709\u4e86\u4e00\u4e2a\u5305\u542b\u7269\u79cd\u51fa\u73b0\u6570\u636e\u7684\u5730\u7406\u7a7a\u95f4\u6570\u636e\u96c6\n# \u8fd9\u4e2a\u6570\u636e\u96c6\u81f3\u5c11\u5305\u542b\u4e24\u5217\uff1a\u7269\u79cd\u662f\u5426\u5b58\u5728\uff081\u8868\u793a\u5b58\u5728\uff0c0\u8868\u793a\u4e0d\u5b58\u5728\uff09\u548c\u5730\u7406\u5750\u6807\n\n# \u52a0\u8f7d\u6570\u636e\u96c6\n# data = gpd.read_file('path_to_your_species_data.shp')\n\n# \u4e3a\u4e86\u793a\u4f8b\uff0c\u6211\u4eec\u521b\u5efa\u4e00\u4e2a\u5047\u7684\u6570\u636e\u96c6\n# \u5047\u8bbe\u6211\u4eec\u6709\u4e24\u4e2a\u73af\u5883\u53d8\u91cf\uff1a\u6e29\u5ea6\u548c\u964d\u6c34\uff0c\u4ee5\u53ca\u7269\u79cd\u51fa\u73b0\u7684\u6570\u636e\ndata = pd.DataFrame({\n    'species_presence': [1, 0, 1, 0, 1],  # \u7269\u79cd\u51fa\u73b0\uff081\uff09\u6216\u4e0d\u5b58\u5728\uff080\uff09\n    'temperature': [22, 15, 30, 18, 25],  # \u6e29\u5ea6\n    'precipitation': [1200, 800, 1500, 900, 1300]  # \u964d\u6c34\u91cf\n})\n</pre> # \u5047\u8bbe\u4f60\u5df2\u7ecf\u6709\u4e86\u4e00\u4e2a\u5305\u542b\u7269\u79cd\u51fa\u73b0\u6570\u636e\u7684\u5730\u7406\u7a7a\u95f4\u6570\u636e\u96c6 # \u8fd9\u4e2a\u6570\u636e\u96c6\u81f3\u5c11\u5305\u542b\u4e24\u5217\uff1a\u7269\u79cd\u662f\u5426\u5b58\u5728\uff081\u8868\u793a\u5b58\u5728\uff0c0\u8868\u793a\u4e0d\u5b58\u5728\uff09\u548c\u5730\u7406\u5750\u6807  # \u52a0\u8f7d\u6570\u636e\u96c6 # data = gpd.read_file('path_to_your_species_data.shp')  # \u4e3a\u4e86\u793a\u4f8b\uff0c\u6211\u4eec\u521b\u5efa\u4e00\u4e2a\u5047\u7684\u6570\u636e\u96c6 # \u5047\u8bbe\u6211\u4eec\u6709\u4e24\u4e2a\u73af\u5883\u53d8\u91cf\uff1a\u6e29\u5ea6\u548c\u964d\u6c34\uff0c\u4ee5\u53ca\u7269\u79cd\u51fa\u73b0\u7684\u6570\u636e data = pd.DataFrame({     'species_presence': [1, 0, 1, 0, 1],  # \u7269\u79cd\u51fa\u73b0\uff081\uff09\u6216\u4e0d\u5b58\u5728\uff080\uff09     'temperature': [22, 15, 30, 18, 25],  # \u6e29\u5ea6     'precipitation': [1200, 800, 1500, 900, 1300]  # \u964d\u6c34\u91cf }) In\u00a0[\u00a0]: Copied! <pre>from shapely import Point\n# \u5c06\u6570\u636e\u8f6c\u6362\u4e3aGeoDataFrame\uff0c\u8fd9\u91cc\u6211\u4eec\u4f7f\u7528\u5047\u7684\u5750\u6807\ndata['geometry'] = pd.Series([\n    Point(-97.73, 30.27),\n    Point(-97.74, 30.29),\n    Point(-97.72, 30.28),\n    Point(-97.75, 30.26),\n    Point(-97.76, 30.30),\n], index=data.index)\n</pre> from shapely import Point # \u5c06\u6570\u636e\u8f6c\u6362\u4e3aGeoDataFrame\uff0c\u8fd9\u91cc\u6211\u4eec\u4f7f\u7528\u5047\u7684\u5750\u6807 data['geometry'] = pd.Series([     Point(-97.73, 30.27),     Point(-97.74, 30.29),     Point(-97.72, 30.28),     Point(-97.75, 30.26),     Point(-97.76, 30.30), ], index=data.index) In\u00a0[\u00a0]: Copied! <pre>gdf = gpd.GeoDataFrame(data, geometry='geometry')\n</pre> gdf = gpd.GeoDataFrame(data, geometry='geometry') In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"species_distribution/01_sdm/#introduction","title":"Introduction\u00b6","text":"<p>Species Distribution Models (SDMs) are ecological tools used to predict the probability of species occurrence based on specific environmental conditions. These models analyze geographic and environmental data of where species have been found to predict the potential distribution range of species. SDMs are very popular in quantitative ecology and constitute the most widely used modeling framework for projecting potential future range shifts of species in global change impact assessments.</p> <p>The inputs for SDMs typically include geo-referenced biodiversity observation data (e.g., individual locations, presence of species, species counts, species richness; the response or dependent variable) and geographic layers of environmental information (e.g., climate, land cover, soil attributes; the predictor or independent variables). Such information is now widely available in digital formats. For example, online repositories provide data on species distributions (e.g., GBIF and OBIS), individual animal locations (e.g., Movebank), climate data (e.g., WorldClim and CHELSA), as well as land cover and other remote sensing products (e.g., Copernicus).</p> <p>The goal of SDMs is relate biodiversity observations at specific sites to the prevailing environmental conditions at those sites, which can be achieved using various statistical and machine learning algorithms. Once the biodiversity-environment relationship is estimated, predictions can be made in space and time by projecting the model onto available environmental layers</p> <p>References:</p> <p>https://damariszurell.github.io/SDM-Intro/</p>"},{"location":"species_distribution/01_sdm_zh/","title":"Introduction in Chinese","text":"In\u00a0[4]: Copied! <pre>import pandas as pd\nimport geopandas as gpd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nimport matplotlib.pyplot as plt\n</pre> import pandas as pd import geopandas as gpd from sklearn.model_selection import train_test_split from sklearn.ensemble import RandomForestClassifier from sklearn.metrics import accuracy_score, confusion_matrix import matplotlib.pyplot as plt   <p>\u5047\u8bbe\u4f60\u5df2\u7ecf\u6709\u4e86\u4e00\u4e2a\u5305\u542b\u7269\u79cd\u51fa\u73b0\u6570\u636e\u7684\u5730\u7406\u7a7a\u95f4\u6570\u636e\u96c6 \u8fd9\u4e2a\u6570\u636e\u96c6\u81f3\u5c11\u5305\u542b\u4e24\u5217\uff1a\u7269\u79cd\u662f\u5426\u5b58\u5728\uff081\u8868\u793a\u5b58\u5728\uff0c0\u8868\u793a\u4e0d\u5b58\u5728\uff09\u548c\u5730\u7406\u5750\u6807</p> <p>\u4e3a\u4e86\u793a\u4f8b\uff0c\u6211\u4eec\u521b\u5efa\u4e00\u4e2a\u5047\u7684\u6570\u636e\u96c6 \u5047\u8bbe\u6211\u4eec\u6709\u4e24\u4e2a\u73af\u5883\u53d8\u91cf\uff1a\u6e29\u5ea6\u548c\u964d\u6c34\uff0c\u4ee5\u53ca\u7269\u79cd\u51fa\u73b0\u7684\u6570\u636e</p> In\u00a0[5]: Copied! <pre>data = pd.DataFrame({\n    'species_presence': [1, 0, 1, 0, 1],  # \u7269\u79cd\u51fa\u73b0\uff081\uff09\u6216\u4e0d\u5b58\u5728\uff080\uff09\n    'temperature': [22, 15, 30, 18, 25],  # \u6e29\u5ea6\n    'precipitation': [1200, 800, 1500, 900, 1300]  # \u964d\u6c34\u91cf\n})\n</pre> data = pd.DataFrame({     'species_presence': [1, 0, 1, 0, 1],  # \u7269\u79cd\u51fa\u73b0\uff081\uff09\u6216\u4e0d\u5b58\u5728\uff080\uff09     'temperature': [22, 15, 30, 18, 25],  # \u6e29\u5ea6     'precipitation': [1200, 800, 1500, 900, 1300]  # \u964d\u6c34\u91cf })  <p>\u4e3a\u6570\u636e\u589e\u52a0\u5730\u7406\u5750\u6807\uff0c\u5c06\u6570\u636e\u8f6c\u6362\u4e3aGeoDataFrame\u3002\u8fd9\u91cc\u6211\u4eec\u4f7f\u7528\u5047\u7684\u5730\u7406\u5750\u6807</p> In\u00a0[7]: Copied! <pre>from shapely import Point\ndata['geometry'] = pd.Series([\n    Point(-97.73, 30.27),\n    Point(-97.74, 30.29),\n    Point(-97.72, 30.28),\n    Point(-97.75, 30.26),\n    Point(-97.76, 30.30),\n], index=data.index)\n</pre> from shapely import Point data['geometry'] = pd.Series([     Point(-97.73, 30.27),     Point(-97.74, 30.29),     Point(-97.72, 30.28),     Point(-97.75, 30.26),     Point(-97.76, 30.30), ], index=data.index)  In\u00a0[8]: Copied! <pre>gdf = gpd.GeoDataFrame(data, geometry='geometry')\n</pre> gdf = gpd.GeoDataFrame(data, geometry='geometry') In\u00a0[9]: Copied! <pre>gdf\n</pre> gdf Out[9]: species_presence temperature precipitation geometry 0 1 22 1200 POINT (-97.73000 30.27000) 1 0 15 800 POINT (-97.74000 30.29000) 2 1 30 1500 POINT (-97.72000 30.28000) 3 0 18 900 POINT (-97.75000 30.26000) 4 1 25 1300 POINT (-97.76000 30.30000) In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"species_distribution/01_sdm_zh/#introduction-in-chinese","title":"Introduction in Chinese\u00b6","text":"<p>\u7269\u79cd\u5206\u5e03\u6a21\u578b\uff08Species Distribution Models\uff0c\u7b80\u79f0SDMs\uff09\u662f\u4e00\u79cd\u7528\u4e8e\u9884\u6d4b\u7269\u79cd\u5728\u7279\u5b9a\u73af\u5883\u6761\u4ef6\u4e0b\u51fa\u73b0\u6982\u7387\u7684\u751f\u6001\u5b66\u5de5\u5177\u3002\u8fd9\u4e9b\u6a21\u578b\u901a\u8fc7\u5206\u6790\u7269\u79cd\u51fa\u73b0\u5730\u70b9\u7684\u5730\u7406\u548c\u73af\u5883\u6570\u636e\uff0c\u6765\u9884\u6d4b\u7269\u79cd\u7684\u6f5c\u5728\u5206\u5e03\u8303\u56f4\u3002 \u7269\u79cd\u5206\u5e03\u6a21\u578b\u5728\u5b9a\u91cf\u751f\u6001\u5b66\u4e2d\u975e\u5e38\u6d41\u884c\uff0c\u5e76\u4e14\u662f\u5168\u7403\u53d8\u5316\u5f71\u54cd\u8bc4\u4f30\u4e2d\u7528\u4e8e\u9884\u6d4b\u7269\u79cd\u6f5c\u5728\u8303\u56f4\u53d8\u5316\u7684\u6700\u5e7f\u6cdb\u4f7f\u7528\u7684\u5efa\u6a21\u6846\u67b6\u3002</p> <p>\u7269\u79cd\u5206\u5e03\u6a21\u578b\u7684\u8f93\u5165\u901a\u5e38\u5305\u62ec\u5730\u7406\u53c2\u8003\u7684\u751f\u7269\u591a\u6837\u6027\u89c2\u6d4b\u6570\u636e\uff08\u4f8b\u5982\u4e2a\u4f53\u4f4d\u7f6e\u3001\u7269\u79cd\u5b58\u5728\u3001\u7269\u79cd\u8ba1\u6570\u3001\u7269\u79cd\u4e30\u5bcc\u5ea6\uff1b\u54cd\u5e94\u6216\u56e0\u53d8\u91cf\uff09\u548c\u73af\u5883\u4fe1\u606f\u7684\u5730\u7406\u56fe\u5c42\uff08\u4f8b\u5982\u6c14\u5019\u3001\u571f\u5730\u8986\u76d6\u3001\u571f\u58e4\u5c5e\u6027\uff1b\u9884\u6d4b\u6216\u81ea\u53d8\u91cf\uff09\u3002\u8fd9\u4e9b\u4fe1\u606f\u73b0\u5728\u5e7f\u6cdb\u4ee5\u6570\u5b57\u5316\u683c\u5f0f\u63d0\u4f9b\u3002\u4f8b\u5982\uff0c\u5728\u7ebf\u5b58\u50a8\u5e93\u63d0\u4f9b\u6709\u5173\u7269\u79cd\u5206\u5e03\u7684\u6570\u636e\uff08\u4f8b\u5982GBIF\u548cOBIS\uff09\u3001\u6709\u5173\u5355\u4e2a\u52a8\u7269\u4f4d\u7f6e\u7684\u6570\u636e\uff08\u4f8b\u5982Movebank\uff09\u3001\u6709\u5173\u6c14\u5019\u7684\u6570\u636e\uff08\u4f8b\u5982WorldClim\u548cCHELSA\uff09\u4ee5\u53ca\u571f\u5730\u8986\u76d6\u548c\u5176\u4ed6\u9065\u611f\u4ea7\u54c1\u7684\u6570\u636e\uff08\u4f8b\u5982Copernicus\uff09\u3002</p> <p>\u7269\u79cd\u5206\u5e03\u6a21\u578b\u7684\u76ee\u7684\u662f\u5c06\u7279\u5b9a\u5730\u70b9\u7684\u751f\u7269\u591a\u6837\u6027\u89c2\u6d4b\u4e0e\u8fd9\u4e9b\u5730\u70b9\u7684\u7279\u5b9a\u73af\u5883\u6761\u4ef6\u8054\u7cfb\u8d77\u6765\uff0c\u53ef\u4ee5\u4f7f\u7528\u4e0d\u540c\u7684\u7edf\u8ba1\u548c\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u6765\u5b9e\u73b0\u8fd9\u4e00\u70b9\u3002\u4e00\u65e6\u4f30\u8ba1\u4e86\u751f\u7269\u591a\u6837\u6027-\u73af\u5883\u5173\u7cfb\uff0c\u6211\u4eec\u53ef\u4ee5\u901a\u8fc7\u5c06\u6a21\u578b\u6295\u5f71\u5230\u53ef\u7528\u7684\u73af\u5883\u56fe\u5c42\u4e0a\uff0c\u5728\u7a7a\u95f4\u548c\u65f6\u95f4\u4e0a\u8fdb\u884c\u9884\u6d4b\u3002</p>"},{"location":"species_distribution/02_gbif_api/","title":"GBIF Python API","text":"In\u00a0[\u00a0]: Copied! <pre>from pygbif import species as species\nfrom pygbif import occurrences as occ\n</pre> from pygbif import species as species from pygbif import occurrences as occ In\u00a0[\u00a0]: Copied! <pre>splist = ['Cyanocitta stelleri', 'Junco hyemalis', 'Aix sponsa',\n  'Ursus americanus', 'Pinus conorta', 'Poa annuus']\nkeys = [ species.name_backbone(x)['usageKey'] for x in splist ]\n</pre> splist = ['Cyanocitta stelleri', 'Junco hyemalis', 'Aix sponsa',   'Ursus americanus', 'Pinus conorta', 'Poa annuus'] keys = [ species.name_backbone(x)['usageKey'] for x in splist ] In\u00a0[\u00a0]: Copied! <pre>out = [ occ.search(taxonKey = x, limit=0)['count'] for x in keys ]\n</pre> out = [ occ.search(taxonKey = x, limit=0)['count'] for x in keys ] In\u00a0[\u00a0]: Copied! <pre>x = dict(zip(splist, out))\nsorted(x.items(), key=lambda z:z[1], reverse=True)\n</pre> x = dict(zip(splist, out)) sorted(x.items(), key=lambda z:z[1], reverse=True)"},{"location":"species_distribution/03_cnn_sdm/","title":"CNN and SDM","text":"In\u00a0[\u00a0]: Copied! <pre>import pandas as pd\n</pre> import pandas as pd In\u00a0[\u00a0]: Copied! <pre>df = pd.read_csv(\n    'data/species_distribution/cnn_sdm/full_dataset.csv',\n    header='infer',\n    sep=';',\n    low_memory=False,\n    )\n</pre> df = pd.read_csv(     'data/species_distribution/cnn_sdm/full_dataset.csv',     header='infer',     sep=';',     low_memory=False,     ) In\u00a0[\u00a0]: Copied! <pre>from pprint import pprint\npprint(df.columns)\n</pre> from pprint import pprint pprint(df.columns) In\u00a0[\u00a0]: Copied! <pre>ids = df['id'].to_numpy()\nlabels = df['Label'].to_numpy()\npositions = df[['Latitude', 'Longitude']].to_numpy()\n</pre> ids = df['id'].to_numpy() labels = df['Label'].to_numpy() positions = df[['Latitude', 'Longitude']].to_numpy() In\u00a0[\u00a0]: Copied! <pre>ids.shape, labels.shape, positions.shape\n</pre> ids.shape, labels.shape, positions.shape In\u00a0[\u00a0]: Copied! <pre>from sklearn.model_selection import train_test_split\n</pre> from sklearn.model_selection import train_test_split In\u00a0[\u00a0]: Copied! <pre>test_size = 0.1\nval_size = 0.1\ntrain_labels, test_labels, train_positions, test_positions, train_ids, test_ids = train_test_split(\n    labels, positions, ids, test_size=test_size,\n)\ntrain_labels, val_labels, train_positions, val_positions, train_ids, val_ids = train_test_split(\n    train_labels, train_positions, train_ids, test_size=val_size,\n)\n</pre> test_size = 0.1 val_size = 0.1 train_labels, test_labels, train_positions, test_positions, train_ids, test_ids = train_test_split(     labels, positions, ids, test_size=test_size, ) train_labels, val_labels, train_positions, val_positions, train_ids, val_ids = train_test_split(     train_labels, train_positions, train_ids, test_size=val_size, ) In\u00a0[\u00a0]: Copied! <pre>print(train_ids.shape, train_labels.shape, train_positions.shape)\nprint(test_ids.shape, test_labels.shape, test_positions.shape)\nprint(val_ids.shape, val_labels.shape, val_positions.shape)\n</pre> print(train_ids.shape, train_labels.shape, train_positions.shape) print(test_ids.shape, test_labels.shape, test_positions.shape) print(val_ids.shape, val_labels.shape, val_positions.shape) In\u00a0[\u00a0]: Copied! <pre>from sunyata.cnn_sdm.raster import PatchExtractor\n</pre> from sunyata.cnn_sdm.raster import PatchExtractor In\u00a0[\u00a0]: Copied! <pre>extractor = PatchExtractor(\"data/species_distribution/cnn_sdm/rasters_GLC19/\")\nextractor.add_all()\n</pre> extractor = PatchExtractor(\"data/species_distribution/cnn_sdm/rasters_GLC19/\") extractor.add_all() In\u00a0[\u00a0]: Copied! <pre>lat, lng = 43.6, 3.8\npatch = extractor[(lat, lng)]\n</pre> lat, lng = 43.6, 3.8 patch = extractor[(lat, lng)] In\u00a0[\u00a0]: Copied! <pre>from sunyata.cnn_sdm.dataset import EnvironmentalDataset\n</pre> from sunyata.cnn_sdm.dataset import EnvironmentalDataset In\u00a0[\u00a0]: Copied! <pre>train_dataset = EnvironmentalDataset(\n    train_labels,\n    train_positions,\n    train_ids,\n    patch_extractor=extractor,\n)\n</pre> train_dataset = EnvironmentalDataset(     train_labels,     train_positions,     train_ids,     patch_extractor=extractor, ) In\u00a0[\u00a0]: Copied! <pre>torch_tensor, label = train_dataset[0]\n</pre> torch_tensor, label = train_dataset[0] In\u00a0[\u00a0]: Copied! <pre>torch_tensor.shape, label.shape\n</pre> torch_tensor.shape, label.shape In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"species_distribution/03_cnn_sdm/#cnn-and-sdm","title":"CNN and SDM\u00b6","text":""}]}