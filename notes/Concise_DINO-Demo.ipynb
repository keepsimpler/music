{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import glob\n",
    "import pickle\n",
    "import os, random, sys\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define colors\n",
    "COLORS = {\n",
    "    'green': '#7fa433',\n",
    "    'red': '#a74a50',\n",
    "    'purple': '#70669e',\n",
    "    'blue': '#3365ac',\n",
    "    'background': '#373e4c',\n",
    "    'secondary': '#414b5d',\n",
    "    'light_bg': '#606e8a' ,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlay_heatmap_on_image(image, attentions, image_idx):\n",
    "    \"\"\"\n",
    "    Overlay a heatmap on an image and plot the result.\n",
    "    \n",
    "    Parameters:\n",
    "    - image: Torch tensor representing the image ([3, H, W])\n",
    "    - attentions: Torch tensor representing the heatmap ([B, 1, H, W])\n",
    "    - image_idx: Index to select the heatmap from the batch\n",
    "    \n",
    "    Returns:\n",
    "    - Plots the original image, heatmap, and overlay side-by-side.\n",
    "    \"\"\"\n",
    "    heatmap = attentions[0][image_idx].unsqueeze(0).squeeze().numpy()\n",
    "    # Normalize the heatmap\n",
    "    heatmap_normalized = (heatmap - heatmap.min()) / (heatmap.max() - heatmap.min())\n",
    "    # Convert image tensor to numpy and create RGBA heatmap\n",
    "    image_np = image.numpy().transpose(1, 2, 0)\n",
    "    heatmap_colored = np.zeros((*image_np.shape[:2], 4))\n",
    "    heatmap_colored[..., 0] = heatmap_normalized   # Red channel\n",
    "    heatmap_colored[..., 3] = heatmap_normalized   # Alpha channel\n",
    "    # Overlay\n",
    "    overlay = np.clip(image_np + heatmap_colored[..., :3] * heatmap_colored[..., 3:4], 0, 1)\n",
    "    # Plot\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    fig.patch.set_facecolor(COLORS['background'])\n",
    "    for a in ax:\n",
    "        a.set_facecolor(COLORS['background'])\n",
    "        a.axis(\"off\")\n",
    "    ax[0].imshow(image_np) \n",
    "    ax[0].set_title(\"Original Image\\n\", fontsize=13, color=COLORS['light_bg']); ax[0].axis(\"off\")\n",
    "    ax[1].imshow(heatmap, cmap='hot')\n",
    "    ax[1].set_title(\"Attention Heatmap\\n\", fontsize=13, color=COLORS['light_bg']); ax[1].axis(\"off\")\n",
    "    ax[2].imshow(overlay)\n",
    "    ax[2].set_title(\"Overlay\\n\", fontsize=13, color=COLORS['light_bg']); ax[2].axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def visualize_attention(unaug_img, dino_instance, device, patch_size=8, \n",
    "                        output_dir='./outputs', head_idx=0, image_idx=0):\n",
    "    \"\"\"\n",
    "    Visualize the attention of a given image using a DINO model instance.\n",
    "    Parameters:\n",
    "    - unaug_img: Torch tensor representing the unaugmented image ([B, 3, H, W])\n",
    "    - dino_instance: Instance of the DINO model\n",
    "    - device: Device to which tensors are moved for model inference\n",
    "    - patch_size: Size of the patches used in the DINO model\n",
    "    - output_dir: Directory where outputs can be saved\n",
    "    - image_idx: Index of the image to be visualized from the batch\n",
    "    Returns:\n",
    "    - Calls overlay_heatmap_on_image and visualizes the original image, attention, and overlay.\n",
    "    \"\"\"\n",
    "    # Process the image\n",
    "    img, bs = unaug_img[image_idx], unaug_img.shape[0]\n",
    "    w, h = img.shape[1] - img.shape[1] % patch_size, img.shape[2] - img.shape[2] % patch_size\n",
    "    img = img[:, :w, :h].unsqueeze(0)\n",
    "    w_featmap = img.shape[-2] // patch_size\n",
    "    h_featmap = img.shape[-1] // patch_size\n",
    "    # Get attentions from the model\n",
    "    attentions = dino_instance.get_last_selfattention(img.to(device))\n",
    "    nh = attentions.shape[1]  # number of head\n",
    "    print(f'Number of heads: {nh}')\n",
    "    print(f'Batch Size: {bs}')\n",
    "    attentions = attentions[0, :, 0, 1:].reshape(nh, -1)\n",
    "    attentions = attentions.reshape(nh, w_featmap, h_featmap)\n",
    "    attentions = nn.functional.interpolate(attentions.unsqueeze(0), scale_factor=patch_size, mode=\"nearest\")\n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    # Visualize using the previously defined function\n",
    "    overlay_heatmap_on_image(unaug_img[image_idx], attentions, head_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
